#!/bin/bash
export GOOGLE_DRIVE_EXPORT_LINK_PREFIX=
export USER_LABEL_DRIVE_FILE_ID=
export TWEET_TEXT_DRIVE_FILE_ID=
export TWEET_JSON_DRIVE_FILE_ID=

# Preprocess only 1/SHARD_DENOMINATOR of data.
# Set this value to 1 to process all datas.
export shard_denominator=1

export num_procs=32
# Whether to generate lookup_by_uid json while preprocessing.
# Required for training but not for embedding.
export enable_indexing=1
export rerun_tokenization=1
export per_user_concatenation=0
export concatenation_delimiter=newline 
# export concatenation_delimiter=space 

export eval_per_device_batch_size=1024
export train_per_device_batch_size=512

# PRNG keys must be integers.
export train_prng_key=0

export learning_rate=0.001
export triplet_threshold=1

# Both eval (forward) and train (forward and backward.)
export max_seq_length=128

# HuggingFace Transformer model
export unittest_base_model_name=
export base_model_name=
export json_suffix=

# Pooling strategies. 
# cls_embedding_with_dense_layer requires a model with a pooling head.
# export pooling_strategy=cls_embedding_with_dense_layer  
export pooling_strategy=cls_embedding_only
# export pooling_strategy=word_embedding_mean

export model_output_path=data/artifacts/political_tweet
export save_every_num_batches=1000